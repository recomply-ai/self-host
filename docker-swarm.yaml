version: '3.8'

x-backend-image: &backend-image us-central1-docker.pkg.dev/propane-bebop-462910-g8/recomply-ai-backend/backend:latest
x-frontend-image: &frontend-image us-central1-docker.pkg.dev/propane-bebop-462910-g8/recomply-ai-frontend/frontend:latest

x-common-environment: &common-environment
  PYTHONPATH: /app/src
  DATABASE_URL: postgresql+asyncpg://postgres:postgres@postgres:5432/recomply_ai
  REDIS_URL: redis://redis:6379/2
  JWT_SECRET_KEY: system-jwt-secret
  ADMIN_USERNAME: admin
  ADMIN_PASSWORD: secret123
  CLIENT_API_KEY: api-key
  BROWSER_USE_BROWSER_BINARY_PATH: /usr/bin/chromium
  LOG_LEVEL: INFO
  APP_ENV: dev
  OPENSANCTIONS_BASE_URL: http://sanctions_app:8000
  OPENSANCTIONS_API_KEY: dummy

  # Need to be populated manually
  GOOGLE_SERVICE_ACCOUNT_CREDS_BASE64: POPULATE_ME_FROM_GOOGLE_SERVICE_ACCOUNT_KEY
  GCP_PROJECT_ID: POPULATE_ME
  GCP_STORAGE_BUCKET_NAME: POPULATE_ME
  GCP_STORAGE_SERVICE_ACCOUNT_CREDS_BASE64: POPULATE_ME_FROM_GOOGLE_SERVICE_ACCOUNT_KEY
  BRIGHT_DATA_CDP_WS_URL: POPULATE_ME
  UK_COMPANIES_HOUSE_API_KEY: POPULATE_ME_ASK_RECOMPLY_TEAM

services:
  sanctions_index:
    image: public.ecr.aws/opensearchproject/opensearch:2.19.3
    environment:
      - node.name=index
      - cluster.name=opensanctions-index
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g"
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=aefgA1oy!hqgjkl
      - plugins.security.disabled=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - sanctions_data:/usr/share/opensearch/data
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - backend

  sanctions_app:
    image: ghcr.io/opensanctions/yente:5.0.1
    environment:
      YENTE_INDEX_TYPE: "opensearch"
      YENTE_INDEX_URL: http://sanctions_index:9200
      YENTE_UPDATE_TOKEN: ""
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    networks:
      - backend


  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: recomply_ai
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d recomply_ai"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - backend

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - backend

  migrations:
    image: *backend-image
    command: sh -c "
      echo 'Waiting for PostgreSQL to be ready...';
      until uv run python -c \"import psycopg2; psycopg2.connect(host='postgres', user='postgres', password='postgres', database='recomply_ai')\"; do
        echo 'PostgreSQL not ready, waiting 5 seconds...';
        sleep 5;
      done;
      echo 'PostgreSQL is ready, running migrations...';
      uv run alembic upgrade head
      "
    environment:
      <<: *common-environment
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
    networks:
      - backend

  api:
    image: *backend-image
    command: sh -c "
      echo 'Waiting for Redis to be ready...';
      until uv run python -c \"import redis; redis.Redis(host='redis', port=6379, db=2).ping()\"; do
        echo 'Redis not ready, waiting 5 seconds...';
        sleep 5;
      done;
      echo 'Waiting for PostgreSQL to be ready...';
      until uv run python -c \"import psycopg2; psycopg2.connect(host='postgres', user='postgres', password='postgres', database='recomply_ai')\"; do
        echo 'PostgreSQL not ready, waiting 5 seconds...';
        sleep 5;
      done;
      echo 'Dependencies ready, starting API server...';
      uv run python -m scripts.run_api_server
      "
    environment:
      <<: *common-environment
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD", "uv", "run", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/docs', timeout=5)"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    networks:
      - backend

  worker:
    image: *backend-image
    command: sh -c "
      echo 'Waiting for Redis to be ready...';
      until uv run python -c \"import redis; redis.Redis(host='redis', port=6379, db=2).ping()\"; do
        echo 'Redis not ready, waiting 5 seconds...';
        sleep 5;
      done;
      echo 'Waiting for PostgreSQL to be ready...';
      until uv run python -c \"import psycopg2; psycopg2.connect(host='postgres', user='postgres', password='postgres', database='recomply_ai')\"; do
        echo 'PostgreSQL not ready, waiting 5 seconds...';
        sleep 5;
      done;
      echo 'Dependencies ready, starting worker...';
      uv run python -m scripts.run_arq_worker
      "
    environment:
      <<: *common-environment
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD", "uv", "run", "python", "-c", "import redis; redis.Redis(host='redis', port=6379, db=2).ping()"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    networks:
      - backend

  frontend:
    image: *frontend-image
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - frontend

  nginx:
    image: nginx:alpine
    environment:
      BACKEND_URL: api:8000
      FRONTEND_URL: frontend:80
    command:
      - /bin/sh
      - -c
      - |
        echo 'Waiting for API to be ready...'
        until wget --quiet --tries=1 --spider http://api:8000/api/docs; do
          echo 'API not ready, waiting 5 seconds...'
          sleep 5
        done
        echo 'Waiting for Frontend to be ready...'
        until wget --quiet --tries=1 --spider http://frontend:80/; do
          echo 'Frontend not ready, waiting 5 seconds...'
          sleep 5
        done
        echo 'Dependencies ready, starting Nginx...'
        envsubst '$$BACKEND_URL $$FRONTEND_URL' < /etc/nginx/templates/nginx.conf.template > /etc/nginx/conf.d/default.conf
        nginx -g 'daemon off;'
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf.template:/etc/nginx/templates/nginx.conf.template:ro
      - nginx_logs:/var/log/nginx
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD", "wget", "--tries=1", "--spider", "http://127.0.0.1:80/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 120s
    networks:
      - frontend
      - backend

networks:
  backend:
    driver: overlay
    attachable: true
  frontend:
    driver: overlay
    attachable: true

volumes:
  sanctions_data:
    driver: local
  postgres_data:
    driver: local
  redis_data:
    driver: local
  nginx_logs:
    driver: local